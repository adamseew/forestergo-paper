
\newcommand{\CLASSINPUTtoptextmargin}{54pt}
\newcommand{\CLASSINPUTbottomtextmargin}{54pt}
\newcommand{\CLASSINPUTinnersidemargin}{54pt}
\newcommand{\CLASSINPUToutersidemargin}{54pt}

\documentclass[letterpaper,10pt,conference,twoside]{IEEEtran}
\IEEEoverridecommandlockouts 
\def\IEEEtitletopspace{21pt}

\usepackage[inline]{enumitem}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage[font=footnotesize]{caption}
\usepackage[font=footnotesize]{subcaption}
\usepackage[noadjust]{cite}

%% package for urls
\usepackage{url}

%% hyperref
% and an override to make hyperref work with ieeetran.cls
\makeatletter
\let\NAT@parse\undefined
\makeatother
\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}
\makeatletter
\newcommand*{\textlabel}[2]{%
  \edef\@currentlabel{#1}% Set target label
  \phantomsection% Correct hyper reference link
  #1\label{#2}% Print and store label
}
\makeatother

\usepackage{cleveref}[2012/02/15]% v0.18.4; 
\crefformat{footnote}{#2\footnotemark[#1]#3}
\usepackage{textpos}
\usepackage{amsthm}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage[scaled]{helvet}
\usepackage{flushend}


\AddToHook{shipout/foreground}{
  \begin{tikzpicture}[remember picture,overlay]
    \node[red,rotate=45,scale=10,opacity=0.2] at (current page.center) {\small\fontfamily{phv}\selectfont%};
     IN~PREPARATION
%    UNDER~REVIEW
};   
  \end{tikzpicture}
}

%% correct bad hyphenation here
\hyphenation{}

\renewcommand{\qedsymbol}{$\blacksquare$}

\theoremstyle{definition}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{assm}[thm]{Assumption}
\newtheorem{cor}{Corollary}
\newtheorem{conj}{Conjecture}[section]
\newtheorem{defn}{Definition}[section]
\newtheorem{exmp}{Example}[section]
\newtheorem{pb}{Problem}[section]
\newtheorem{rem}{Remark}
\newtheorem{obs}{Observation}
\newtheorem*{ctb}{Contribution}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\makeatletter
\newcommand\notsotiny{\@setfontsize\notsotiny\@vipt\@viipt}
\makeatother

\renewcommand\citepunct{,\hspace*{.8ex}}
\renewcommand*{\citedash}{--}

\begin{document}
\bstctlcite{IEEEexample:BSTcontrol}

\title{\LARGE\bf Scaling Ergodic Control for Large-Scale Problems:\\Robotic Exploration with a Moving Gaussian Mixture Model}

\author{Adam Seewald${}^{\text{1}}$, Ian Abraham${}^{\text{2}}$, and Stefano Mintchev${}^{\text{1}}$
  \thanks{This work was partly supported by ETH Z{\"u}rich's World Food System Center and Yale University.}
  \thanks{${}^{\text{1}}$A.\hspace*{.4ex}S. and S.\hspace*{.4ex}M. are with the Department of Environmental Systems Science, ETH Z{\"u}rich, Switzerland. Email: {\tt\footnotesize \href{mailto:aseewald@ethz.ch}{aseewald@ethz.ch};}}
  \thanks{${}^{\text{2}}$I.\hspace*{.4ex}A. is with the Department of Mechanical Engineering and Materials Science, Yale University, CT, USA.}
}

\maketitle

%\vspace*{.5cm}
\begin{abstract}
  The problem of exploring unknown and large-scale spaces with robots arises in many real-world applications. While different approaches exist, those utilizing sensory data have emerged as of particular interest. Among these, ergodic control is significant, as it accounts for both motion cost and optimality. However, ergodic controllers often encounter limitations when applied to large-scale problems. This paper introduces a general and scaled ergodic control methodology designed to overcome these limitations. Unlike traditional ergodic controllers that rely on predefined information measures or separate obstacle avoidance, our approach dynamically generates and refines the information measure from sensory data and derives a degree of obstacle avoidance as a ``by-product.'' Empirical data from simulations in diverse environments, including dense vegetation and agricultural settings, demonstrate the effectiveness of our scaled general ergodic control, showcasing the applicability of our methodology compared to conventional techniques typically restricted to structured or small-scale only.
\end{abstract}


\IEEEpubidadjcol
%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\noindent
% story line, ergodic search is great because blah blah
% there has been a lot of developments recently, but
% no one is really scaling ergodic control to real and large-scale pb.
% here we do that with the concept of a moving GMM
% moreover, existing approaches rely on external techniques for obstacle avoidance (e.g., the cbfs Cameron's been using)
% here we propose a a methodology that has a degree of obstacle avoidance as a "by-product."
% BUT WHY IS ERGO EXCITING?
% Deep fundamental challenges linking machine learning, optimal control, signal processing and information theory
% Achieves manipulation tasks robustly, by not only relying on accurate sensors, but instead using a control strategy to cope with limited or inaccurate sensing information
% Different from stochastic or patterned search! → Provides a natural way of searching
Exploring unknown and potentially large-scale spaces with robots is a problem commonly addressed by different methodologies arising in computing and robotics. This problem is recurring in real-world use cases such as monitoring, reconstruction, exploration, etc., where robots are expected to cover a given space while performing an assigned task. A key challenge to the practical applicability of these methodologies is that of leveraging resources while, at the same time, maximizing the information gathered and optimizing the exploration accordingly~\cite{popovic2020informative,schmid2020efficient}. 
While there are different approaches in the literature, approaches that are informed by sensory data have emerged as of particular interest. Among these approaches, ergodic control is a significant result, as it provides a more natural way of searching through deterministic exploratory behaviors while accounting for both the motion cost and optimality~\cite{miller2016ergodic}.

Ergodic control is a planning and controls methodology that derives robot trajectories maximizing a given information measure so that robots spend more time in areas with high information measure while quickly traversing areas with low information measure~\cite{mathew2011metrics,abraham2017ergodic,miller2013trajectory}. As a consequence, it is required that the user provides an information measure a priori or that the information measure is derived as the robots gather more information about their surroundings. While applicable to some use cases, this is often a limitation of the existing ergodic controllers. It is not always the case that the information measure can be easily refined from the gathered data, or that an a priori information measure can be provided at all. Furthermore, it is also not always feasible to define an information measure for large-scale spaces. % in practice. 
With this work, we address this challenge. We provide a general and scaled ergodic control methodology that can be applied to a broader class of robotic use cases. Our methodology does not require an underlying information measure but rather, derives an information measure from the exploration itself and refines such a measure utilizing information about already visited areas and obstacles. %from sensory data. 
In contrast to existing ergodic control methodologies that require external obstacle avoidance techniques, e.g., control barrier functions~\cite{lerch2023safety}, optical flow~\cite{prabhakar2020ergodic}, etc., our methodology provides additionally a tunable degree of obstacle avoidance as a ``by-product.'' 
%
The underlying information measure is represented utilizing a Gaussian Mixture Model (GMM), which is refined from the sensory data as the robot traverses the state space -- a process that is handled by our methodology and that does not require any user input. Our ergodic formulation is different from existing methods. The problem is posed so that the robot spends time in areas with low information measures, whereas the ``explored space'' is related to high information measures. The methodology is iterative and utilizes a model predictive controller (MPC) approach, where the ergodic controller is refined within a specified time window.

\IEEEpubidadjcol
Existing ergodic controllers have been studied from the point of view of time~\cite{dong2023time} and energy~\cite{seewald2024energy,naveed2024eclares} optimality and applied to a multitude of use cases. These use cases include tactile sensing~\cite{abraham2017ergodic}, active learning~\cite{abraham2021ergodic}, multi-objective optimality~\cite{ren2023pareto,srinivasan2023multi}, grasping and manipulation~\cite{shetty2022ergodic,bilaloglu2023whole}, and visual rendering~\cite{low2022drozbot,prabhakar2020autonomous}. Ergodic controllers in the literature feature diverse aspects such as stochastic dynamics~\cite{torre2016ergodic,ayvali2017ergodic} and multi-agent and/or swarm control with both centralized~\cite{seewald2024energy,rao2024learning} and distributed information processing~\cite{prabhakar2020ergodic,coffin2022multi}. Although some of these use cases involve information gathering~\cite{dressel2018optimality} and feature urban environments and other potentially large-scale problems~\cite{prabhakar2020ergodic,rao2023multi}, a generic large-scale ergodic controller has not been studied yet. Even though recent methods have been making progress in this direction~\cite{whittemeyer2023bi,seewald2024energy,naveed2024eclares,dong2023time}, these methods do not scale efficiently due to the formulation of the underlying optimization and/or require an a priori information measure. From an obstacle avoidance perspective, even though there are ergodic controllers that feature obstacle avoidance~\cite{lerch2023safety}, this is an external component on top of the ergodic controller that then results in a sub-ergodic solution~\cite{dong2023time} rather than an integral component of the explorer itself.

We showcase our general and scaled ergodic control on a large-scale problem: the problem of exploring a simulated forest and an outdoor area that has both dense vegetation and an agricultural setting, in contrast to existing ergodic control methodologies that are demonstrated in structured environments or generally in small-scale only. Section~\ref{sec:res} shows the performance of our methods. The open-source software stack to replicate our approach and the experimental data are made available on our project repository webpage\footnote{\href{https://github.com/adamseew/scaledergo}{\tt github.com/adamseew/scaledergo}}.

The remainder of this paper is structured as follows. Sec.~\ref{sec:pb} provides the details of the underlying principles and the problem addressed. Sec.~\ref{sec:meth} is split into two sub-sections: one provides an overview of ergodic control, whereas the other details our methodology. Sec.~\ref{sec:conc} provides conclusions and draws future perspectives.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem Formulation}\label{sec:pb}
\noindent
This work addresses the problem of exploring a bounded and potentially large-scale space, where ``large-scale'' refers to spaces on the order of dozens or even hundreds of meters in both the x- and y-axes. For practical reasons, we restrict the exploration space to one hectare and consider exploration in two dimensions. However, the formulation is such that the state space could potentially be unbounded and not limited to two dimensions~\cite{dong2023time}.

Let us consider a bounded space $\mathcal{Q}\subset\mathbb{R}^2$. The robot is free to move in this space except for a finite number of obstacles~represented by $\mathcal{O}\subset\mathcal{Q}$. In the remainder, we utilize the concepts of ergodicity and ergodic metric to direct the robot into unexplored areas (i.e., with low information density) while avoiding the obstacles, i.e., $\mathcal{Q}\,\,\cap\,\,\mathcal{O}$, as opposed to other approaches featuring ergodic control in the literature where exploration happens in areas with high information density instead~\cite{mathew2011metrics,abraham2017ergodic,miller2013trajectory}.

\begin{defn}[Ergodicity]
  Given the bounded state space $\mathcal{Q}$, a trajectory $\mathbf{x}(t)\in\mathcal{Q}$ is \textit{ergodic} with respect to a spatial distribution $\phi$, or, analogously, is distributed among regions of high expected distribution, if and only if
  \begin{equation}
    \lim_{t\rightarrow\infty}{\int_{\mathcal{Q}}\phi(\mathbf{x})\Omega(\mathbf{x})\,d\mathbf{x}=\frac{1}{t}\int_{\mathcal{T}}{{\Omega\big(\overline{\mathbf{x}}(t)\big)}}\,dt},
  \end{equation}
  where $\overline{\,\cdot\,}$ is a map that maps the state space to the exploration spaces, and $\Omega$ are all the Lebesgue functions as defined in, e.g.,~\cite{mathew2011metrics}.
\end{defn}

The spatial distribution $\phi$ is constructed using a Gaussian Mixture Model (GMM). 
\begin{defn}[Moving GMM]\label{def:movement}
  Assume that there is a given number $n\in\mathbb{N}_{>0}$ of Gaussians $\mathcal{N}$ in a GMM, with an initial probability equally distributed. A \textit{moving GMM} is \begin{equation}
    \phi(\boldsymbol{\alpha},\boldsymbol{\mu},\mathbf{x}):=\sum_{i=1}^n{\alpha_i\,\mathcal{N}_i(\mathbf{x}\,|\,\mu_i,\Sigma_i)},
  \end{equation}
  where $\Sigma_i\in\mathbb{R}^{2\times 2}$ indicates the covariance matrix and $\mu_i\in\mathcal{Q}$ denotes the center of a Gaussian $\mathcal{N}_i$. 
\end{defn}

The GMM defined in this way has variable centers $\boldsymbol{\mu}\in\mathcal{Q}^n$ and variable mixing coefficients $\boldsymbol{\alpha}\in\mathbb{R}_{>0}^n$.

The notation $\mathbb{S}_{>0}$ denotes a strictly positive set $\mathbb{S}$. Bold letters indicate vectors, i.e., $\mathbf{x}\in\mathcal{Q}$ is the state space vector, whereas $\boldsymbol{\alpha}$, $\boldsymbol{\mu}$  are the vectors comprising the ideal GMM's mixing coefficients and position components respectively (see Sec.~\ref{sec:meth}).

An ergodic metric is then defined as a value that quantifies the ergodicity.
\begin{defn}[Ergodic metric]\label{def:ergomet}
  Consider a time average distribution of the trajectory over a limited time window $t$, e.g.,
  \begin{equation}
    h\big(\mathbf{x}(t)\big):=\frac{1}{t}\int_\mathcal{T}\Delta\big((\mathbf{x})(t)\big)\,dt,
  \end{equation}
  where $\Delta$ is defined as a Dirac delta function. An \textit{ergodic metric} is an $L^2$-inner product in between the average of the spatial and time distributions.
\end{defn}

\begin{pb}[Scaled ergodic control]\label{pb}
  Given the state space and the obstacles space $\mathcal{Q}$ and $\mathcal{O}$ respectively, assume the number of Gaussian components $n$ is given. The \textit{scaled ergodic control} problem is the problem of finding the evolution of the Gaussian components of a moving GMM, i.e., $\boldsymbol{\alpha}(t)$ and $\boldsymbol{\mu}(t)$ and of the control $\mathbf{u}(t)\in\mathcal{U}$ so that $\mathbf{x}(t)$ explores $\mathcal{Q}$ while avoiding $\mathcal{O}$ \textit{and} the ergodic metric is minimized.
\end{pb}

Note that it is not a requirement that the obstacle space $\mathcal{O}$ is known at the beginning of the exploration.

We propose a solution to Problem~\ref{pb} and demonstrate experimentally the feasibility of the solution, highlighting the trade-offs between accuracy (i.e., coverage) and exploration soundness (i.e., obstacle avoidance capabilities) in Sec.~\ref{sec:res1} and~\ref{sec:res2} respectively.


%%%%%%%%%%%%%%%%%%
\section{Methods}\label{sec:meth}
\noindent
This section details our methods. Sec.~\ref{sec:canon} introduces the concept of canonical ergodic control for exploration in bounded areas with an information density distribution. Sec.~\ref{sec:sol} describes our methodology of scaled ergodic control, i.e., ergodic control with a moving information density as a function of explored versus unexplored space.

\subsection{Canonical ergodic control}
\label{sec:canon}
\noindent
To quantify the time average and the average of the spatial distributions $h$ and $\phi$ respectively, we use Fourier series basis functions, a common method for evaluating distributions in the spectral domain~\cite{mathew2011metrics}. For the time average distribution, the coefficients of an equivalent basis function can be expressed as
\begin{equation}\label{eq:ck}
  c_k\big(\mathbf{x}(t)\big):=\int_{\mathcal{T}}{\prod_{d\in\{1,2\}}}{\cos{\big(2\pi k_d\mathbf{x}_d(\tau)/T\big)}/T^2}\,d\tau/t,
\end{equation}
where $T\in\mathbb{R}_{>0}$ is a given period and $\,\cdot\,_d$ denotes the $d$th item of a vector.

Equation~(\ref{eq:ck}) expresses the cosine basis function for a coefficient $k$, considering only the positive slice of the spectral domain and thus ignoring the function's imaginary component. The coefficients $k\in\mathcal{K}$ depend on a given number of frequencies $\kappa\in\mathbb{N}_{>0}$, including the base frequency, and are constructed so that $\mathcal{K}\in\mathbb{N}^2$ is a set of index vectors covering the set $\kappa\times\cdots\times\kappa\in\mathbb{N}^{\kappa^2}$, i.e., they are built so that the coefficients are evaluated over the entire domain~\cite{calinon2020mixture}.

For the average of the spatial distribution, the coefficients of an equivalent basis function can be expressed similarly as 
\begin{equation}\label{eq:phik}
  \phi_k(\mathbf{x}):=\int_{\mathcal{Q}}{\sum_{d\in\{1,2\}}}{\phi(\mathbf{x})c(\mathbf{x})\,d\mathbf{x}},
\end{equation}
where $c$ is the integrand in Eq.~(\ref{eq:ck}) at the given point $\mathbf{x}$, evaluated at the current time step.

The aim of an ergodic controller is to minimize an ergodic metric, i.e., the $L^2$-inner product of the distributions $h$ and $\phi$ (see Definition~\ref{def:ergomet}). A consolidated metric~\cite{abraham2017ergodic,abraham2021ergodic,seewald2024energy,lerch2023safety,abraham2018decentralized,dong2023time} for this purpose is, for instance, \begin{equation}
  \mathcal{E}(\mathbf{x}):=\sum_{k\in\mathcal{K}}{\Lambda_k(c_k-\phi_k)^2/2},
\end{equation}
where the coefficients of the time average and the average spatial distributions are expressed in Eq.~(\ref{eq:ck}--\ref{eq:phik}).

$\Lambda_k$ is a weight factor that determines the importance of different frequencies, e.g., with
\begin{equation}
  \Lambda_k:=\frac{1}{\sqrt{\big(1+\lVert{k}\rVert^2\big)^3}},
\end{equation}
lower frequencies are preferred.

Note that in Eq.~(\ref{eq:phik}) we have utilized the expression for a standard GMM. 
We use the expression for the moving GMM defined in Definition~\ref{def:movement} (i.e., GMM with variable centers and mixing coefficients) in the next section.












\subsection{Scaled ergodic control}
\label{sec:sol}
\noindent
To utilize the concept of moving information density as a function of explored versus unexplored space, let us first consider Eq.~(\ref{eq:phik}) with the moving GMM.

Assume for practical purposes that the space is square, with a given length $l\in\mathbb{R}_{>0}$ expressed in meters. We then restrict the period in Eq.~(\ref{eq:ck}) to this search space and express $l$ as $T/2$. Eq.~(\ref{eq:phik}) can also be expressed as 
\begin{equation}
  \phi_k(\boldsymbol{\alpha},\boldsymbol{\mu},\mathbf{x})\hspace*{-.6ex}:=\hspace*{-1ex}\int_{\mathcal{Q}}{\hspace*{-1ex}\Bigg(\hspace*{-.3ex}\sum_{d\in\{1,2\}}\hspace*{-.5ex}\sum_{i=1}^n\alpha_i\mathcal{N}_i\big(\mathbf{x\,|\,\overline{\rule{0pt}{2.4mm}{\mu_i}},\overline{\Sigma_i}}\big)\hspace*{-.5ex}\Bigg)\hspace*{-.1ex}c(\mathbf{x})\,d\mathbf{x}},
\end{equation}
where $\overline{\,\cdot\,}$ is a map that maps the center and the covariance matrix to a symmetric state space delimited by $-l$ and $l$, e.g., a map that uses linear transformation matrices~\cite{calinon2020mixture}.

We further define a value that represents the concept of ``history.'' If this value is expressed by $h\in\mathbb{R}_{>0}$, we can model the space that has already been explored by the robot using the definition of the moving GMM. The covariance matrix can be expressed as 
\begin{equation}
  \Sigma_i:=\frac{1}{2T}\int_\Upsilon\sum_{d\in\{1,2\}}{\big(\mathbf{x}_d(\tau)-\mu_i\big)}\,d\tau,
\end{equation}
where the trajectory is evaluated within the history, i.e., $\Upsilon$ indicates the time interval between $t$ and $t-h$.

The centers can then be expressed as $\mu_i:=E\big(\mathbf{x}(t)\big)$, with $E$ being the expected value of $\mathbf{x}$ on $\Upsilon$. 

The scaled ergodic control problem is thus framed as finding an ergodic controller that targets the inverse of the probability distribution represented by the moving GMM, thereby avoiding areas “already visited” within a given history window $h$. However, this formulation may produce trajectories that require an additional obstacle avoidance methodology, such as~\cite{lerch2023safety}.


\begin{figure}[t!]
  \begin{minipage}[t!]{.25\columnwidth}
    \caption[.]{\textbf{.   }.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . }
    \label{fig:0}
  \end{minipage}\hspace*{.3cm}
  \begin{minipage}[t!]{.7\columnwidth}
    \vspace*{-.3cm}
    \input{figures/compare.pdf_tex}
  \end{minipage}
  \vspace*{-.4cm}
  \caption*{\footnotesize .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .}
\end{figure}

Let us consider a modified expression for the center of the Gaussian
\begin{equation}
  \mu_i:=E\big(\mathbf{x}(t)\big)-e_i
\end{equation}
where $e_i\in\mathbf{e}\subset\mathbb{R}^n$ represents a displacement that allows for ``moving'' the Gaussian components in the moving GMM.

Our methodology ensures that the scaled ergodic controller determines the minimum displacement of the Gaussians so that the space to be visited is delimited by $\mathcal{Q}\,\,\cap\,\,\mathcal{O}$. This controller can be formulated as an optimal control problem (OCP) 
\begin{subequations}\label{eq:ocp}\begin{align}
  \min_{\Theta}%\int_{\mathcal{T}}\mathbf{u}(\tau)^TR\mathbf{u}(\tau)\,d\tau+
  \mathcal{E}&(\mathbf{x})+\Psi(\mathbf{e}),\label{eq:cost}\\
  \text{s.t. }\dot{\mathbf{x}}&=f(\mathbf{x}(t),\mathbf{u}(t)),\label{eq:dyn}\\
  \mathbf{x}&(t)\in\mathcal{Q}\cap\mathcal{O},\,\mathbf{u}(t)\in\mathcal{U},\label{eq:const}\\
  \mathbf{x}&(t_0),n,\kappa,l,h,\text{ are given},\label{eq:ocpconsttotf}
\end{align}\end{subequations}
where the output of the optimization $\Theta$ in Eq.~(\ref{eq:cost}) is $\mathbf{x},\mathbf{u},\boldsymbol{\alpha},\boldsymbol{\mu}$, i.e., the center of each Gaussian and its mixing coefficient in the moving GMM, as functions of the control and the state. The function $\Psi$ maps the displacement to a cost value, e.g., 
\begin{equation}
  \Psi(\mathbf{e}):=\sum_{e_i\in\mathbf{e}}|e_i|,
\end{equation}
where $|\hspace{.2ex}\cdot\hspace{.2ex}|$ is defined as an $L^2$-norm.

The dynamics in Eq.~(\ref{eq:dyn}) represent a 2D single integrator system, which approximates the behavior of an unmanned aerial vehicle (UAV) in our experimental setup to a reasonable extent (see Sec.~\ref{sec:res}).

The problem is formulated to determine the displacement and probability for each Gaussian and the optimal (i.e., ergodic) control, ensuring that the displacement and probability deviate minimally from the ideal case. Note that the Gaussians represent the history of the explored space. For practical purposes, a defined horizon $N \in \mathbb{N}_{>0}$ is used, and the optimization is iterated for each horizon using a methodology similar to an MPC controller, where $\mathcal{T}$ in Eq.~(\ref{eq:ck}) denotes the interval between $t$ and $t-N$ (with $N$ not to be confused with the history window $h$).

Large-scale exploration is considered complete when a desired level of coverage is achieved (see Sec.~\ref{sec:res}). It is also possible to configure the problem so that exploration continues indefinitely or for extended periods, as discussed in~\cite{seewald2022energy}. %TODO!

Additional practical considerations, such as the choice of history and the size of the moving GMM, are detailed in the next section.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental Results}\label{sec:res}
\noindent
This section provides an overview of our experimental setup and showcases the results. 
Experiments are conducted using \textsc{Matlab}~(R), while interfaces for physical experimental evaluation are supported by a routine implemented in Python. The MPC optimization stack, which solves the OCP in Eq.~(\ref{eq:ocp}), relies on two external open-source components: the non-linear programming solver IPOPT~\cite{wachter2006implementation} and the algorithmic differentiation library CasADi~\cite{andersson2012casadi}.

In the following sections, Sec.~\ref{sec:res1} presents experimental results from a simulated forest with an area of 3~600~square~meters. Sec.~\ref{sec:res2} details our findings regarding the built-in obstacle avoidance capabilities of our general scaled ergodic controller compared to its coverage performance. Sec.~\ref{sec:res3} describes the outdoor modeled results, featuring an area with both dense vegetation and an agricultural setting, including multiple obstacles and a total area of 10~000 square meters.

\begin{figure}[t!]
  \centering
  \begin{subfigure}[t]{\linewidth}
  \hspace*{-.15cm}\input{figures/__steps_1.pdf_tex}
  \caption{\textbf{.   }.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .}
  \label{fig:1-1}
  \end{subfigure}
  \vspace*{.1cm}
  \begin{subfigure}[t]{\linewidth}
  \hspace*{-.15cm}\input{figures/_steps_2.pdf_tex}
  \caption{\textbf{.   }.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .}
  \label{fig:1-2}
  \end{subfigure}
  \vspace*{.1cm}
  \begin{subfigure}[t]{\linewidth}
  \hspace*{-.15cm}\input{figures/_steps_3.pdf_tex}
  \caption{\textbf{.   }.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .}
  \label{fig:1-3}
  \end{subfigure}
  \caption[.]{\textbf{.   }.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .}
  \label{fig:1}
\end{figure}




\subsection{Simulated forest}\label{sec:res1}
\noindent
Simulated results are conducted in a forest with 45 trees randomly distributed across an area of 3~600 square meters. The history $h$ is set to 100 time steps (see Sec.~\ref{sec:res2}). The simulation is terminated at 50~000 time steps when a desired coverage threshold is achieved within a specified approximation (i.e., 60\%~$\pm$5\%). The number of Gaussians $n$ is set to five, with the initial positions centered in the middle of the state space. The number of frequencies $\kappa$ is set to nine, excluding the base frequency, consistent with other ergodic controllers in the literature~\cite{seewald2022energy}. %todo

Fig.~\ref{fig:1} presents the results for the simulated forest at distinct time steps. Fig.~\ref{fig:1-1} shows the trajectory (on the right) after 1~000 time steps. The history is illustrated with a dark red line, and the current point is marked by a dark red dot. The top-left of the figure depicts the underlying information density distribution (i.e., the moving GMM from Definition~\ref{def:movement}), including a detail of the five Gaussian components in the area representing the current history interval. The optimal values of the Gaussian centers $\boldsymbol{\mu}$ and the mixing coefficients $\boldsymbol{\alpha}$ ensure that the moving GMM represents the history (i.e., the expected value and covariance of the trajectory over the current history window) while minimizing deviation to avoid obstacles. The bottom-left of the figure displays the coverage map, where each square counts the number of points within it at a given time.

Fig.~\ref{fig:1-2} shows the trajectory at time instant 2~500. The simulated UAV continues navigating through the obstacles, further exploring the state space. The moving GMM is shown on the top right, and the coverage map is displayed at the bottom right.

Fig.~\ref{fig:1-3} shows the trajectory at time instant 10~000. As with the previous figures, the moving GMM model and coverage map are illustrated at the top-left and bottom-left, respectively. It is observed that while the obstacles are generally avoided, the simulated UAV occasionally comes close to or passes through obstacles. A relationship between the degree of obstacle avoidance and coverage is reported, as discussed in the following section.





\begin{figure}[t!]
  \begin{minipage}[t!]{.67\columnwidth}
    \hspace*{.1cm}\input{figures/phys.pdf_tex}
  \end{minipage}\hspace*{.6cm}
  \begin{minipage}[t!]{.25\columnwidth}
    \caption[.]{\textbf{.   }.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .}
    \vspace*{-.2cm}
    \label{fig:2}
  \end{minipage}
  \vspace*{-.2cm}
  \caption*{\footnotesize .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .}
\end{figure}

\subsection{Obstacle avoidance vs. coverage}\label{sec:res2}
\noindent
The OCP formulated in Eq.~(\ref{eq:ocp}) may not always yield an optimal solution. In such cases, our algorithm provides a sub-optimal solution where the constraint in Eq.~(\ref{eq:const}) may not be fully respected. For example, in the simulated trees scenario described in Sec.~\ref{sec:res1}, obstacles may not be avoided within the desired threshold. We observed this behavior during the initial iterations of our scaled ergodic methodology. However, by tuning our approach using the concept of history $h$, we can improve obstacle avoidance as a by-product of our method.

Fig.~\ref{fig:0} presents our experimental results, highlighting the trade-offs between built-in obstacle avoidance capabilities and coverage, along with a collision metric. The collision metric $c_e$ is designed to count every occurrence where a point violates the constraint in Eq.~(\ref{eq:const}) within a given threshold. The count of violations is shown on the left y-axis of the figure. With a horizon set to 50~000, the invalidation ratio for a history window of zero is only 0.044\%, whereas it increases to 0.46\% for a history window of 1~000. The threshold for invalidation is set to 60 centimeters. Coverage is calculated as described in Sec.~\ref{sec:res1}. Note that full coverage is not achieved since obstacles are included in the overall coverage metric.

The top of the figure shows the three metrics on a logarithmic scale. We observed that a history window of 100 provides the best trade-off between obstacle avoidance (0.14\%) and coverage metrics. The bottom of the figure displays a detailed view of the history window around 100, $\pm$25.

\subsection{Outdoors model}\label{sec:res3}
\noindent
Additional experimental evaluation is conducted using a model of an outdoor vegetated area located in Birmensdorf, ZH, Switzerland, with coordinates 47.362646\textdegree~latitude and 8.457228\textdegree~longitude. The area was selected to include both dense vegetation and an agricultural setting, simulating a real-world use case for our general scaled ergodic controller. The exploration area is bounded to 10~000 square meters, and the surrounding region has been manually surveyed to assess future feasibility.

Fig..~\ref{fig:2} illustrates the path taken, with the history represented by the dark-red line and the current point marked by the dark red dot. The history is set to 150 time steps, and the dynamics in Eq.~(\ref{eq:dyn}) are adjusted to reasonably model a DJI (R) Mavic 3 UAV. The history is chosen to ensure obstacle avoidance, allowing the UAV to navigate within the vegetation while avoiding tree trunks.

Physical experimental evaluation was performed on an initial segment of the overall trajectory, demonstrating the potential feasibility of the method using ergodic controllers. The actual path is derived from MATLAB (R). Further physical evaluation is ongoing (see Sec.~\ref{sec:conc}). Exploratory trajectories are imported into the UAV's flight controller using waypoints, managed by proprietary software; however, compatibility with other software and flight controllers is supported. Data are reported after a horizon of 5~000 time steps. The obstacles are positioned so that the UAV operates within the canopy at an altitude of 2.5 meters, excluding small bushes but including tree trunks. The UAV's velocity is set to 1.5 meters per second.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion and Future Directions}\label{sec:conc}
\noindent
.

~
\newpage

{\small
\bibliographystyle{IEEEtran} 
\bibliography{forestergo}
}

\end{document}

% 20.07